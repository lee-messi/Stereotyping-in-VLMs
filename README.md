# More Distinctively Black and Feminine Faces Lead to Increased Stereotyping in Vision-Language Models

The abstract for the paper is as follows:

> Recent advancements have brought artificial intelligence (AI) closer to simulating human-like perception through the development of Vision Language Models (VLMs). These models, exemplified by GPT-4V, adeptly integrate textual and visual data, building on the capabilities of Large Language Models. However, despite their advanced abilities, VLMs inherit biases of both modalities. Our study explores how VLMs perpetuate racial and gender stereotypes, focusing on homogeneity bias and trait associations. We find that GPT-4V represents subordinate racial and gender groups with greater homogeneity than their dominant group counterparts and distinct, generally positive traits that diverge from typical racial and gender stereotypes. Importantly, we find that greater racial prototypicality and femininity lead to more VLM stereotyping. We explore the underlying reasons behind this behavior and discuss its implications, emphasizing the importance of addressing these biases as VLMs come to mirror human perception. 

This paper is under review, but comments are still very welcome. Please feel free to open an "Issue" here. For detailed instructions for reproducing analysis, refer to the [Instructions.md](Instructions.md) document.

## Data Availability Statement

This repository does not include all data files: Large (100MB+) .csv and .RData files containing cosine similarity measures for homogeneity bias assessment are not made available, but they can be reproduced using the provided code. Image files from the Chicago Face Databse (Ma et al., 2015) are not made available. These files can be obtained from [the Chicago Face Database website](https://www.chicagofaces.org/). 
